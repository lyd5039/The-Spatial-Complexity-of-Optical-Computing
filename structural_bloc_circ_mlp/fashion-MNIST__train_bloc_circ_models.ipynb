{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79c9470-6622-42e1-904e-efc2c563e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('structural_bloc_circ_utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f421355-8e58-4648-b1ff-40f659373715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deff4636-d8a2-49a9-8a6f-9a84cd7e5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from StructuralBlocCircModel import StructuralBlocCircModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b5f47-3282-4fd0-875f-b88ead30dedb",
   "metadata": {},
   "source": [
    "### test block circulant matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c11b54-7dcd-49d8-84be-85679bb7d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloc_circ_linear_layer import BlocCircLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21374bc7-adfb-4a9b-a262-474f9a4774ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from forward method:\n",
      "tensor([[ 5.5332,  0.8648,  3.4750,  1.9541, -5.0767, -5.2086,  0.9053,  3.0476],\n",
      "        [ 3.9707, -2.1824,  1.4220,  3.8938, -8.7572,  0.2643,  0.2022, -1.6428],\n",
      "        [-2.0725,  4.2697,  3.9691, -5.7047, -4.0770,  1.2386, -1.6909,  0.7616]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "\n",
      "Result from manual multiplication with full matrix A:\n",
      "tensor([[ 5.5332,  0.8648,  3.4750,  1.9541, -5.0767, -5.2086,  0.9053,  3.0476],\n",
      "        [ 3.9707, -2.1824,  1.4220,  3.8938, -8.7572,  0.2643,  0.2022, -1.6428],\n",
      "        [-2.0725,  4.2697,  3.9691, -5.7047, -4.0770,  1.2386, -1.6909,  0.7616]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "The results match!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BlocCircLinear layer with the specified dimensions\n",
    "row_dim = 8\n",
    "col_dim = 12\n",
    "n_blocks = 4\n",
    "layer = BlocCircLinear(row_dim=row_dim, col_dim=col_dim, n_blocks=n_blocks)\n",
    "\n",
    "# Generate a random input tensor x with batch size 3 and appropriate input dimensions\n",
    "batch_size = 3\n",
    "x = torch.randn(batch_size, col_dim)\n",
    "\n",
    "# Method 1: Use the forward method of BlocCircLinear to perform matrix multiplication\n",
    "y_forward = layer(x)\n",
    "\n",
    "# Method 2: Manually get the full circulant matrix A and perform matrix multiplication\n",
    "A = layer.get_full_circ_mat()\n",
    "y_manual = torch.matmul(x, A.T)  # A.T because we're multiplying from the right\n",
    "\n",
    "# Print the results\n",
    "print(\"Result from forward method:\")\n",
    "print(y_forward)\n",
    "\n",
    "print(\"\\nResult from manual multiplication with full matrix A:\")\n",
    "print(y_manual)\n",
    "\n",
    "# Check if the results are close\n",
    "if torch.allclose(y_forward, y_manual, atol=1e-6):\n",
    "    print(\"\\nThe results match!\")\n",
    "else:\n",
    "    print(\"\\nThere is a discrepancy between the results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c579f9-3e5f-4606-a73d-a1b771a6653d",
   "metadata": {},
   "source": [
    "### train and save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda8474f-d007-4664-8da3-c49c6e2cd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs__StructuralCircDiagModels__bias=False_nonlinearity=SiLU__every_layer_except_last.json', 'r') as file:\n",
    "    bloc_circ_configs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30a24c1-6b66-48db-8c79-f3948dd57ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a different MNIST-like dataset, replace 'fashion-MNIST' with 'MNIST' or 'Kuzushiji-MNIST'\n",
    "training_config = {\n",
    "    'dataset': 'fashion-MNIST',\n",
    "    'starting_learning_rate': 0.005,\n",
    "    'weight_decay': 2e-5,\n",
    "    'scheduler': 'cosine annealing',\n",
    "    'T_max': 200,\n",
    "    'eta_min': 1e-05,\n",
    "    'stopping_epoch': 200,\n",
    "    'train_loader_batch_size': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f03968-0349-4ac5-ab61-98051708952b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed17d52-1e8f-4156-a1ab-29b46779d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MNIST = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_MNIST = torchvision.datasets.MNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "train_fashion_MNIST = torchvision.datasets.FashionMNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_fashion_MNIST = torchvision.datasets.FashionMNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "train_Kuzushiji_MNIST = torchvision.datasets.KMNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_Kuzushiji_MNIST = torchvision.datasets.KMNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a94842-5a9d-4342-9b4a-5f4cb9f623a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "list_rand_seeds = [random.randint(0, 2**32 - 1) for _ in range(8)]\n",
    "print(list_rand_seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d496f0c-7e51-48f3-a6ac-ec9ae2d007c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_time_zone = pytz.timezone('US/Eastern')\n",
    "\n",
    "\n",
    "list_config_names = ['config2', 'config3', 'config4', 'config5', 'config6', 'config7']\n",
    "\n",
    "for config_name in list_config_names:\n",
    "    for rand_seed in list_rand_seeds:\n",
    "\n",
    "        dict_to_save = {\n",
    "            'model_name': bloc_circ_configs[config_name]['model_name'],\n",
    "            'dataset': training_config['dataset'],\n",
    "            'layer_sizes': bloc_circ_configs[config_name]['layer_sizes'],\n",
    "            'config_name': bloc_circ_configs[config_name]['config_name'],\n",
    "            'n_blocks_list': bloc_circ_configs[config_name]['n_blocks_list'],\n",
    "            'if_bias': bloc_circ_configs[config_name]['if_bias'],\n",
    "            'nonlinear_activation': bloc_circ_configs[config_name]['nonlinear_activation'],\n",
    "            'starting_learning_rate': training_config['starting_learning_rate'],\n",
    "            'weight_decay': training_config['weight_decay'],\n",
    "            'scheduler': training_config['scheduler'],\n",
    "            'T_max': training_config['T_max'],\n",
    "            'eta_min': training_config['eta_min'],\n",
    "            'stopping_epoch': training_config['stopping_epoch'],\n",
    "            'train_loader_batch_size': training_config['train_loader_batch_size'],\n",
    "            'random_seed': rand_seed\n",
    "        }\n",
    "\n",
    "        print(dict_to_save)\n",
    "\n",
    "\n",
    "        ### model folder directory\n",
    "        dir_sbc_model_folder = (\n",
    "            f\"structural_bloc_circ_dataset={dict_to_save['dataset']}\"\n",
    "            f\"\\\\models__dataset={dict_to_save['dataset']}_\"\n",
    "            f\"bias={dict_to_save['if_bias']}_\"\n",
    "            f\"nonlinearity={dict_to_save['nonlinear_activation']}\"\n",
    "        )\n",
    "        df_path = os.path.join(f\"structural_bloc_circ_dataset={dict_to_save['dataset']}\",\n",
    "                               f\"test_results__SBCmodels__dataset={dict_to_save['dataset']}\"\n",
    "                               f\"_bias={dict_to_save['if_bias']}\"\n",
    "                               f\"_nonlinearity={dict_to_save['nonlinear_activation']}.csv\")\n",
    "        if os.path.exists(df_path):\n",
    "            df_results = pd.read_csv(df_path)\n",
    "        else:\n",
    "            df_results = pd.DataFrame()\n",
    "\n",
    "\n",
    "        if dict_to_save['dataset'] == 'MNIST':\n",
    "            train_data = train_MNIST\n",
    "            test_data  = test_MNIST\n",
    "        elif dict_to_save['dataset'] == 'fashion-MNIST':\n",
    "            train_data = train_fashion_MNIST\n",
    "            test_data  = test_fashion_MNIST\n",
    "        elif dict_to_save['dataset'] == 'Kuzushiji-MNIST':\n",
    "            train_data = train_Kuzushiji_MNIST\n",
    "            test_data  = test_Kuzushiji_MNIST\n",
    "        else:\n",
    "            raise ValueError(\"Unknown dataset name\")\n",
    "        \n",
    "\n",
    "        torch.manual_seed(dict_to_save['random_seed'])\n",
    "        np.random.seed(dict_to_save['random_seed'])\n",
    "        \n",
    "        train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=dict_to_save['train_loader_batch_size'])\n",
    "        test_loader = DataLoader(dataset=test_data, shuffle=False, batch_size=1000)\n",
    "\n",
    "\n",
    "        # Initialize the model\n",
    "        sbc_model = StructuralBlocCircModel(\n",
    "            layer_sizes=dict_to_save['layer_sizes'],\n",
    "            n_blocks_list=dict_to_save['n_blocks_list'],\n",
    "            if_bias=dict_to_save['if_bias'],\n",
    "            nonlinearity=dict_to_save['nonlinear_activation']\n",
    "        )\n",
    "        sbc_model.to(device)\n",
    "        \n",
    "        # Initialize the loss function and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(sbc_model.parameters(),\n",
    "                                lr=dict_to_save['starting_learning_rate'],\n",
    "                                weight_decay=dict_to_save['weight_decay'])\n",
    "\n",
    "        if dict_to_save['scheduler'] == 'cosine annealing':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=dict_to_save['T_max'], eta_min=dict_to_save['eta_min'])\n",
    "        else:\n",
    "            raise ValueError(\"scheduler is unspecified\")\n",
    "\n",
    "\n",
    "        t_start = time.time()\n",
    "\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "\n",
    "\n",
    "        for epoch in range(dict_to_save['stopping_epoch']):\n",
    "            epoch_start_time = time.time()  # Start timing the epoch\n",
    "        \n",
    "            sbc_model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "        \n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "                # Resize images from 28x28 (784) to 800\n",
    "                images = images.view(images.size(0), -1)\n",
    "                images = nn.functional.pad(images, (0, 16))  # Add 16 zeros to match size 800\n",
    "        \n",
    "                optimizer.zero_grad()\n",
    "                outputs = sbc_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "                running_loss += loss.item()\n",
    "        \n",
    "                # Calculate training accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "            scheduler.step()\n",
    "        \n",
    "            # Save loss and accuracy only every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                train_loss = running_loss / len(train_loader)\n",
    "                train_accuracy = 100 * correct_train / total_train\n",
    "        \n",
    "                train_losses.append(train_loss)\n",
    "                train_accuracies.append(train_accuracy)\n",
    "        \n",
    "                print(f\"Epoch [{epoch+1}/{dict_to_save['stopping_epoch']}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "                elapsed_time = time.time() - epoch_start_time\n",
    "                print(f\"Time for Epoch [{epoch+1}/{dict_to_save['stopping_epoch']}]: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "            \n",
    "            # Check if it's the last epoch\n",
    "            if (epoch + 1) == dict_to_save['stopping_epoch']:\n",
    "                final_train_loss = running_loss / len(train_loader)\n",
    "                final_train_accuracy = 100 * correct_train / total_train\n",
    "        \n",
    "                sbc_model.eval()\n",
    "                correct_test = 0\n",
    "                total_test = 0\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_loader:\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        images = images.view(images.size(0), -1)\n",
    "                        images = nn.functional.pad(images, (0, 16))\n",
    "        \n",
    "                        outputs = sbc_model(images)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total_test += labels.size(0)\n",
    "                        correct_test += (predicted == labels).sum().item()\n",
    "        \n",
    "                final_test_accuracy = 100 * correct_test / total_test\n",
    "                print(f\"Final Training Loss: {final_train_loss:.4f}, Final Training Accuracy: {final_train_accuracy:.2f}%, Final Test Accuracy: {final_test_accuracy:.2f}%\")\n",
    "        \n",
    "                \n",
    "        # Report epoch duration\n",
    "        t_end = time.time()\n",
    "        \n",
    "\n",
    "        current_time_est = datetime.datetime.now(EST_time_zone)\n",
    "        time_str = current_time_est.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "\n",
    "        dict_to_save['time'] = time_str\n",
    "        dict_to_save['train_losses'] = ', '.join(f\"{loss:.8f}\" for loss in train_losses) # save in string format\n",
    "        dict_to_save['train_accuracies'] = ', '.join(f\"{loss:.4f}\" for loss in train_accuracies) # save in string format\n",
    "        dict_to_save['train_accuracy'] = final_train_accuracy\n",
    "        dict_to_save['test_accuracy'] = final_test_accuracy\n",
    "        dict_to_save['time_consumption(s)'] = t_end - t_start\n",
    "        \n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(list(range(10, dict_to_save['stopping_epoch']+1, 10)), train_accuracies, label='test accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('test accuracy')\n",
    "        plt.title(f\"{dict_to_save['config_name']}, rand_seed={dict_to_save['random_seed']}\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        # save result to spreadsheet\n",
    "        df_results = pd.concat([df_results, pd.DataFrame([dict_to_save])], ignore_index=True)\n",
    "        df_results.to_csv(df_path, index=False)\n",
    "        \n",
    "        \n",
    "        ### save the model\n",
    "        torch.save(sbc_model.state_dict(), f\"{dir_sbc_model_folder}/{dict_to_save['model_name']}__data={dict_to_save['dataset']}__{time_str}.pt\")\n",
    "        torch.save(optimizer.state_dict(), f\"{dir_sbc_model_folder}/optimizer__{dict_to_save['model_name']}__data={dict_to_save['dataset']}__{time_str}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f9054-8e28-4b24-94a6-ccf4d3d161a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (LSONN)",
   "language": "python",
   "name": "lsonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
