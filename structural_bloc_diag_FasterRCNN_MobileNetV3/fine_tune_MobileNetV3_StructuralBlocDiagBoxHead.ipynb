{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952b09c-125b-4e37-8f53-01b955263484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.detection import fasterrcnn_mobilenet_v3_large_fpn, FasterRCNN_MobileNet_V3_Large_FPN_Weights\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8896894-1727-474f-bc24-d6a286249090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloc_diag_model.BlocDiagBoxHead import BlocDiagBoxHead\n",
    "from bloc_diag_model.StructuralBlocDiagBoxHead import StructuralBlocDiagBoxHead\n",
    "from utils.train_utils import train_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39496845-6d36-4851-86f7-8a3b54e6ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a90c25-3ba6-4617-ba08-0ceda1d0e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained weights and model\n",
    "weights = FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT\n",
    "model = fasterrcnn_mobilenet_v3_large_fpn(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c6a48a-fd05-4afe-84d0-8e7ee1b6426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = model.roi_heads.box_head.fc6.in_features\n",
    "num_classes = 91\n",
    "\n",
    "\n",
    "original_box_head = model.roi_heads.box_head\n",
    "\n",
    "custom_box_head = BlocDiagBoxHead([12544, 1024, 1024], [[64]*16, [1024]], [[784]*16, [1024]], True)\n",
    "\n",
    "custom_box_head.fc6.load_state_dict(original_box_head.fc6.state_dict())\n",
    "custom_box_head.fc7.load_state_dict(original_box_head.fc7.state_dict())\n",
    "\n",
    "model.roi_heads.box_head = custom_box_head.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939cac6a-b60e-4cd7-970a-b3cf9d422d97",
   "metadata": {},
   "source": [
    "### Load trained model with block-diagonal BoxHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1399bf-cfe3-414f-9372-2a6207320dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_epoch = 3\n",
    "lambda_offdiag = 1e-4\n",
    "model_timestamp_start = '2025-04-28_14-16-04'\n",
    "\n",
    "model_save_path = os.path.join('./saved_models',\n",
    "                               f\"model_BlocDiagBoxHead__lambda_offdiag={lambda_offdiag}__n_total_epoch={n_total_epoch}__{model_timestamp_start}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8cd9ec-d956-495b-b65a-8480b55f0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388a61b-2371-4779-97c6-b761847865ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc6_weight = model.roi_heads.box_head.fc6.weight.data.clone()\n",
    "fc6_bias = model.roi_heads.box_head.fc6.bias.data.clone()\n",
    "fc7_weight = model.roi_heads.box_head.fc7.weight.data.clone()\n",
    "fc7_bias = model.roi_heads.box_head.fc7.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8c845-9726-48ec-8512-052911c49c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc6_weight_cpu = fc6_weight.detach().cpu().numpy()\n",
    "\n",
    "# Plot the weight matrix\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.imshow(fc6_weight_cpu, aspect='auto', interpolation='nearest', cmap='viridis', vmin=-0.01, vmax=0.01)\n",
    "plt.colorbar(label='Weight value')\n",
    "plt.title('fc6 Weight Matrix')\n",
    "plt.xlabel('Input Features')\n",
    "plt.ylabel('Output Neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1865522-eeb7-406c-a54e-89b8a32a3f04",
   "metadata": {},
   "source": [
    "### Load weights into structural block-diagonal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb43285-41b9-4b37-b747-8782aec12b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_structural_box_head = StructuralBlocDiagBoxHead([12544, 1024, 1024], [[64]*16, [1024]], [[784]*16, [1024]], True)\n",
    "# Load the weights into the new head\n",
    "custom_structural_box_head.fc6.set_blocks_from_full_matrix(fc6_weight, fc6_bias)\n",
    "custom_structural_box_head.fc7.set_blocks_from_full_matrix(fc7_weight, fc7_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38c36d-722c-4426-9fae-df9b4430dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roi_heads.box_head = custom_structural_box_head.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e026b3-0d94-447a-9a4a-9d483bc302a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76e4b0-42ae-4997-9f40-858676838812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the official transform used during pretraining\n",
    "transform = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5fd01f-c40c-4cfe-a9d1-652428257ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/coco\"\n",
    "train_img_folder = os.path.join(data_dir, \"train2017\")\n",
    "train_ann_file = os.path.join(data_dir, \"annotations/instances_train2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac93a58a-09d8-4bbd-b53a-4bf18538320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20000\n",
    "subset_indices = list(range(N))\n",
    "dataset_raw = torch.utils.data.Subset(CocoDetection(train_img_folder, train_ann_file), subset_indices)\n",
    "dataset = []\n",
    "for i in range(N):\n",
    "    img, target = dataset_raw[i]\n",
    "    img_id = dataset_raw.dataset.ids[dataset_raw.indices[i]]\n",
    "    transformed_img = transform(img)\n",
    "    for t in target:\n",
    "        t[\"image_id\"] = img_id\n",
    "    dataset.append((transformed_img, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1199c8-c1f8-427c-ab24-ed2629f8b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd0839-3f48-466d-b05d-f6d5c3fe84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=coco_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79b502-582d-489a-94a5-e3894495e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55e108-b8c1-43a1-bdb2-6337e6b22499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_total_epoch = 2\n",
    "timestamp_start = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "\n",
    "for epoch_num in range(n_total_epoch):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_one_epoch(model, data_loader, optimizer, epoch_num=epoch_num+1, n_total_epoch=n_total_epoch,\n",
    "                    device=device,\n",
    "                    metrics_path=os.path.join('./saved_models', f\"fine_tune_metrics__{timestamp_start}.csv\"),\n",
    "                    lambda_offdiag=None)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Epoch {epoch_num+1}/{n_total_epoch} completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "model_save_path = os.path.join('./saved_models',\n",
    "                               f\"model_StructuralBlocDiagBoxHead__n_total_epoch={n_total_epoch}__{timestamp_start}.pt\")\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7847f-f3aa-4127-99f0-8b992bb2e6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1c13b-5953-44ea-97f3-09b74a3e7e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1936aa-03ff-416d-9495-13e8fdf3b9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de23bbb6-9b43-4b58-8ede-2daa6d338668",
   "metadata": {},
   "source": [
    "#### Fine-tuned model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e477a-4b72-4915-90bd-8c24f90fb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_structural_box_head = StructuralBlocDiagBoxHead([12544, 1024, 1024], [[64]*16, [1024]], [[784]*16, [1024]], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855058c9-270f-4afd-b8da-c8a9b3d4428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.roi_heads.box_head = custom_structural_box_head.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec041b1-d386-46d3-8c42-3961f1d4ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_epoch = 2\n",
    "model_timestamp_start = '2025-04-29_23-29-17'\n",
    "\n",
    "model_save_path = os.path.join('./saved_models',\n",
    "                               f\"model_StructuralBlocDiagBoxHead__n_total_epoch={n_total_epoch}__{model_timestamp_start}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a70b42-7e79-41c9-b6c0-6795a3f26c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e63a4f-b398-4fb8-a0c5-87c7b446aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eval_utils import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753faf3-023c-4272-9ec0-9f1d23f9a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transform used during pretraining\n",
    "transform = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359ba5e-2228-4be9-a66d-00e178153a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to COCO val2017\n",
    "data_dir = \"data/coco\"\n",
    "val_img_folder = os.path.join(data_dir, \"val2017\")\n",
    "val_ann_file = os.path.join(data_dir, \"annotations/instances_val2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e582a4-1e6d-4102-b53d-370a97edd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc8f5b-5c1a-44e1-8846-e2b6cb885786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and apply transform manually to images only\n",
    "dataset_raw = CocoDetection(val_img_folder, val_ann_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547d7f3-7b09-4f8f-bfe2-fa2c08fc3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(len(dataset_raw)):\n",
    "    img, target = dataset_raw[i]\n",
    "    img_id = dataset_raw.ids[i]\n",
    "    transformed_img = transform(img)\n",
    "    for t in target:\n",
    "        t[\"image_id\"] = img_id\n",
    "    dataset.append((transformed_img, target))\n",
    "\n",
    "val_data_loader = DataLoader(dataset, batch_size=8, shuffle=False, collate_fn=coco_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315973af-7b18-4bc5-a493-9f8440e627ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using pycocotools\n",
    "coco_gt = dataset_raw.coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08f17b-4f95-42a7-8256-59cfb6632a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file_path = os.path.join('./model_eval_results', f\"coco_val_results__fine_tuned_model__{model_timestamp_start}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99183e7-cd2c-45b3-b994-f4149ea98a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_data_loader, device=device,\n",
    "               output_path=eval_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f8692-e6b9-48c8-8f8b-06610546a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dt = coco_gt.loadRes(eval_file_path)\n",
    "eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "eval.evaluate()\n",
    "eval.accumulate()\n",
    "eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9e319-e096-45d5-adf9-0ceeb3b1f0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99540013-8d64-4e55-ab7a-412455738155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94e108a7-22fd-4995-9a95-936927e60e30",
   "metadata": {},
   "source": [
    "### View the weight of the structural block-diagonal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc8e5c0-575b-48e4-b7a4-aea454095549",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc6_weight = model.roi_heads.box_head.fc6.get_full_matrix()\n",
    "#fc6_bias = model.roi_heads.box_head.fc6.bias.clone()\n",
    "fc7_weight = model.roi_heads.box_head.fc7.get_full_matrix()\n",
    "#fc7_bias = model.roi_heads.box_head.fc7.bias.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff5f5d-8d2e-4037-8e4a-6edce5200b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.imshow(fc6_weight, aspect='auto', interpolation='nearest', cmap='viridis', vmin=-0.01, vmax=0.01)\n",
    "plt.colorbar(label=\"Weight Value\")\n",
    "plt.title(\"Weight Matrix\")\n",
    "plt.xlabel(\"Input Features\")\n",
    "plt.ylabel(\"Output Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2135b6-f119-476b-bc55-e7fbf536e4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (LSONN_MobileViT)",
   "language": "python",
   "name": "lsonn_mobilevit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
